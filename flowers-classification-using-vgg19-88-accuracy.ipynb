{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport keras\nfrom keras.models import Sequential, Model\nfrom keras.layers import Dense, Conv2D , MaxPool2D , Flatten , Dropout , MaxPooling2D\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report,confusion_matrix\nfrom keras.applications import VGG19\nimport cv2\nimport os\nimport random\nimport tensorflow as tf","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading the Dataset","metadata":{}},{"cell_type":"code","source":"labels = ['dandelion', 'daisy','tulip','sunflower','rose']\nimg_size = 224\ndef get_data(data_dir):\n    data = [] \n    for label in labels: \n        path = os.path.join(data_dir, label)\n        class_num = labels.index(label)\n        for img in os.listdir(path):\n            try:\n                img_arr = cv2.imread(os.path.join(path, img), cv2.IMREAD_COLOR)\n                resized_arr = cv2.resize(img_arr, (img_size, img_size)) # Reshaping images to preferred size\n                data.append([resized_arr, class_num])\n            except Exception as e:\n                print(e)\n    return np.array(data)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = get_data(\"/kaggle/input/flowers-recognition/flowers\")","metadata":{"_kg_hide-output":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Visualization and Preprocessing","metadata":{}},{"cell_type":"code","source":"l = []\nfor i in data:\n    l.append(labels[i[1]])\nsns.set_style('dark')\nsns.countplot(l)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**The dataset seems balanced as for each training label , enough training examples exist**","metadata":{}},{"cell_type":"markdown","source":"**Randomly Previewing first 10 images**","metadata":{}},{"cell_type":"code","source":"fig,ax=plt.subplots(5,2)\nfig.set_size_inches(15,15)\nfor i in range(5):\n    for j in range (2):\n        l=random.randint(0,len(data))\n        ax[i,j].imshow(data[l][0])\n        ax[i,j].set_title('Flower: '+labels[data[l][1]])\n        \nplt.tight_layout()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x = []\ny = []\n\nfor feature, label in data:\n    x.append(feature)\n    y.append(label)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**We perform a grayscale normalization to reduce the effect of illumination's differences.Moreover the CNN converges faster on [0..1] data than on [0..255].**","metadata":{}},{"cell_type":"code","source":"# Normalize the data\nx = np.array(x) / 255","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Reshaping the data from 1-D to 3-D as required through input by CNN's \nx = x.reshape(-1, img_size, img_size, 3)\ny = np.array(y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelBinarizer\nlabel_binarizer = LabelBinarizer()\ny = label_binarizer.fit_transform(y)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train,x_test,y_train,y_test = train_test_split(x , y , test_size = 0.2 , stratify = y , random_state = 0)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Training the Model","metadata":{}},{"cell_type":"code","source":"\npre_trained_model = VGG19(input_shape=(224,224,3), include_top=False, weights=\"imagenet\")\n\nfor layer in pre_trained_model.layers:\n    layer.trainable = False\n\nmodel = Sequential([\n    pre_trained_model,\n    MaxPool2D((2,2) , strides = 2),\n    Flatten(),\n    Dense(5 , activation='softmax')])\nmodel.compile(optimizer = \"adam\" , loss = 'categorical_crossentropy' , metrics = ['accuracy'])\nmodel.summary()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.callbacks import ReduceLROnPlateau\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience = 2, verbose=1,factor=0.3, min_lr=0.000001)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(x_train,y_train, batch_size = 64 , epochs = 12 , validation_data = (x_test, y_test),callbacks = [learning_rate_reduction])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Loss of the model is - \" , model.evaluate(x_test,y_test)[0])\nprint(\"Accuracy of the model is - \" , model.evaluate(x_test,y_test)[1]*100 , \"%\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Analysis after Model Training","metadata":{}},{"cell_type":"code","source":"epochs = [i for i in range(12)]\nfig , ax = plt.subplots(1,2)\ntrain_acc = history.history['accuracy']\ntrain_loss = history.history['loss']\nval_acc = history.history['val_accuracy']\nval_loss = history.history['val_loss']\nfig.set_size_inches(20,10)\n\nax[0].plot(epochs , train_acc , 'go-' , label = 'Training Accuracy')\nax[0].plot(epochs , val_acc , 'ro-' , label = 'Testing Accuracy')\nax[0].set_title('Training & Testing Accuracy')\nax[0].legend()\nax[0].set_xlabel(\"Epochs\")\nax[0].set_ylabel(\"Accuracy\")\n\nax[1].plot(epochs , train_loss , 'g-o' , label = 'Training Loss')\nax[1].plot(epochs , val_loss , 'r-o' , label = 'Testing Loss')\nax[1].set_title('Training & Testing Loss')\nax[1].legend()\nax[1].set_xlabel(\"Epochs\")\nax[1].set_ylabel(\"Loss\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#  Training the Model 2","metadata":{}},{"cell_type":"code","source":"pre_trained_model = VGG19(input_shape=(224,224,3), include_top=False, weights=\"imagenet\")\n\nfor layer in pre_trained_model.layers:\n    layer.trainable = False\n\nfor layer in pre_trained_model.layers [-5:]:\n    layer.trainable = True\n\nmodel = Sequential([\n    pre_trained_model,\n    MaxPool2D((2,2) , strides = 2),\n    Flatten(),\n    Dense(5 , activation='softmax')])\nmodel.compile(optimizer = \"adam\" , loss = 'categorical_crossentropy' , metrics = ['accuracy'])\nmodel.summary()\n\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.callbacks import ReduceLROnPlateau\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience = 2, verbose=1,factor=0.3, min_lr=0.000001)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"history = model.fit(x_train,y_train, batch_size = 64 , epochs = 12 , validation_data = (x_test, y_test),callbacks = [learning_rate_reduction])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"Loss of the model is - \" , model.evaluate(x_test,y_test)[0])\nprint(\"Accuracy of the model is - \" , model.evaluate(x_test,y_test)[1]*100 , \"%\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Analysis after Model Training","metadata":{}},{"cell_type":"code","source":"epochs = [i for i in range(12)]\nfig , ax = plt.subplots(1,2)\ntrain_acc = history.history['accuracy']\ntrain_loss = history.history['loss']\nval_acc = history.history['val_accuracy']\nval_loss = history.history['val_loss']\nfig.set_size_inches(20,10)\n\nax[0].plot(epochs , train_acc , 'go-' , label = 'Training Accuracy')\nax[0].plot(epochs , val_acc , 'ro-' , label = 'Testing Accuracy')\nax[0].set_title('Training & Testing Accuracy')\nax[0].legend()\nax[0].set_xlabel(\"Epochs\")\nax[0].set_ylabel(\"Accuracy\")\n\nax[1].plot(epochs , train_loss , 'g-o' , label = 'Training Loss')\nax[1].plot(epochs , val_loss , 'r-o' , label = 'Testing Loss')\nax[1].set_title('Training & Testing Loss')\nax[1].legend()\nax[1].set_xlabel(\"Epochs\")\nax[1].set_ylabel(\"Loss\")\nplt.show()","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}